---
# the secret used by the `oauth-proxy` sidecar container of Prometheus to authenticate users on GitHub
apiVersion: v1
kind: Secret
metadata:
  namespace: openshift-user-workload-monitoring
  name: prometheus-proxy-config
  labels:
    provider: sandbox-sre
data:
  client-id: PROMETHEUS_GITHUB_CLIENT_ID
  client-secret: PROMETHEUS_GITHUB_CLIENT_SECRET
  cookie-secret: PROMETHEUS_GITHUB_COOKIE_SECRET
type: Opaque

---
# The `prometheus/prometheus` resource triggers the deployment of the Prometheus pods
apiVersion: monitoring.coreos.com/v1
kind: Prometheus
metadata:
  namespace: openshift-user-workload-monitoring
  name: prometheus
  labels:
    provider: sandbox-sre
    app.kubernetes.io/instance: prometheus
spec:
  alerting:
    alertmanagers:
    - name: alertmanager-operated
      namespace: openshift-user-workload-monitoring
      port: web
      scheme: http
  image: quay.io/prometheus/prometheus:v2.25.2
  logLevel: debug
  replicas: 2
  retention: 45d
  walCompression: true
  ruleSelector:
    matchLabels:
      prometheus: sandbox-sre
  serviceAccountName: prometheus-k8s
  serviceMonitorSelector:
    matchLabels:
      prometheus: sandbox-sre
  ruleNamespaceSelector:
    matchLabels:
      openshift.io/workload-monitoring: "true"
  storage:
    volumeClaimTemplate:
      apiVersion: v1
      kind: PersistentVolumeClaim
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 50Gi
        storageClassName: gp2
  version: v2.25.2
  volumeMounts:
    - mountPath: /etc/prometheus/tls
      name: secret-prometheus-oauth2-tls
  volumes:
  - name: secret-prometheus-oauth2-tls
    secret:
      secretName: prometheus-oauth2-tls
  - name: secret-prometheus-oauth-tls
    secret:
      secretName: prometheus-oauth-tls
  containers:
  # extra container to have an access to the Prometheus console to human users who need to login via GitHub
  - name: oauth2-proxy
    args:
    - --provider=github
    - --https-address=:9091
    - --email-domain=*
    - --upstream=http://localhost:9090
    - --tls-cert-file=/etc/tls/private/tls.crt
    - --tls-key-file=/etc/tls/private/tls.key
    - --skip-auth-regex=^/metrics
    - --skip-auth-regex=^/ping
    - --github-org=codeready-toolchain-teams
    - --github-team=observability
    env:
    - name: OAUTH2_PROXY_CLIENT_ID
      valueFrom:
        secretKeyRef:
          key: client-id
          name: prometheus-proxy-config
    - name: OAUTH2_PROXY_CLIENT_SECRET
      valueFrom:
        secretKeyRef:
          key: client-secret
          name: prometheus-proxy-config
    - name: OAUTH2_PROXY_COOKIE_SECRET
      valueFrom:
        secretKeyRef:
          key: cookie-secret
          name: prometheus-proxy-config
    image: quay.io/pusher/oauth2_proxy:v6.1.1
    imagePullPolicy: Always
    ports:
    - name: oauth2-proxy
      containerPort: 9091
      protocol: TCP
    readinessProbe:
      failureThreshold: 3
      periodSeconds: 10
      successThreshold: 1
      httpGet:
        scheme: HTTPS
        port: oauth2-proxy
        path: /ping
      timeoutSeconds: 1
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File
    volumeMounts:
    - mountPath: /etc/tls/private
      name: secret-prometheus-oauth2-tls
  # extra container to have an access to Prometheus from Grafana, using a SA token
  - name: oauth-proxy
    image: quay.io/openshift/origin-oauth-proxy:4.9.0
    imagePullPolicy: IfNotPresent
    ports:
    - name: oauth-proxy
      containerPort: 9092
      protocol: TCP
    args:
    - --https-address=:9092
    - --provider=openshift
    - --openshift-service-account=prometheus-k8s
    - --upstream=http://localhost:9090
    - --tls-cert=/etc/tls/private/tls.crt
    - --tls-key=/etc/tls/private/tls.key
    - --cookie-secret=SECRET
    # see https://github.com/openshift/oauth-proxy/#delegate-authentication-and-authorization-to-openshift-for-infrastructure
    - --openshift-delegate-urls={"/":{"group":"","resource":"namespaces","verb":"get"}}
    volumeMounts:
    - mountPath: /etc/tls/private
      name: secret-prometheus-oauth-tls

---
# Route and service to provide a secured access to the Prometheus console
# via the oauth2-proxy sidecar (ie, that's the route for the human beings)
apiVersion: route.openshift.io/v1
kind: Route
metadata:
  namespace: openshift-user-workload-monitoring
  name: prometheus
  labels:
    provider: sandbox-sre
  annotations:
    kubernetes.io/tls-acme: "true"
spec:
  to:
    kind: Service
    name: prometheus-oauth2
  port:
    targetPort: oauth2-proxy
  tls:
    insecureEdgeTerminationPolicy: Redirect
    termination: reencrypt

---
apiVersion: v1
kind: Service
metadata:
  namespace: openshift-user-workload-monitoring
  name: prometheus-oauth2
  labels:
    provider: sandbox-sre
    app.kubernetes.io/instance: prometheus
  annotations:
    service.alpha.openshift.io/serving-cert-secret-name: prometheus-oauth2-tls
spec:
  ports:
  - name: oauth2-proxy
    port: 9091
    protocol: TCP
    targetPort: 9091
  selector:
    app.kubernetes.io/instance: prometheus

---
# Route and service to provide a secured access to the Prometheus console
# via the oauth-proxy sidecar (ie, that's the route for Grafana with a Service Account token)
apiVersion: route.openshift.io/v1
kind: Route
metadata:
  namespace: openshift-user-workload-monitoring
  name: prometheus-oauth
  labels:
    provider: sandbox-sre
  annotations:
    kubernetes.io/tls-acme: "true"
spec:
  to:
    kind: Service
    name: prometheus-oauth
  port:
    targetPort: oauth-proxy
  tls:
    termination: reencrypt

---
apiVersion: v1
kind: Service
metadata:
  namespace: openshift-user-workload-monitoring
  name: prometheus-oauth
  labels:
    provider: sandbox-sre
    app.kubernetes.io/instance: prometheus
  annotations:
    service.alpha.openshift.io/serving-cert-secret-name: prometheus-oauth-tls
spec:
  ports:
  - name: oauth-proxy
    port: 9092
    protocol: TCP
    targetPort: 9092
  selector:
    app.kubernetes.io/instance: prometheus

# ServiceMonitors
# 1 resource per target to configure

---
# Host Operator
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  namespace: openshift-user-workload-monitoring
  name: sandbox-host-operator
  labels:
    prometheus: sandbox-sre
spec:
  endpoints:
  - bearerTokenSecret:
      name: PROMETHEUS_K8S_SECRET_NAME
      key: token
    interval: 15s
    scheme: https
    tlsConfig: 
      insecureSkipVerify: true
    port: https
  namespaceSelector:
    matchNames:
    - toolchain-host-operator
  selector:
    matchLabels:
      control-plane: "controller-manager"
      operators.coreos.com/toolchain-host-operator.toolchain-host-operator: ""
      
---
# Loki
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  namespace: openshift-user-workload-monitoring
  name: loki
  labels:
    prometheus: sandbox-sre
spec:
  endpoints:
  - bearerTokenSecret:
      name: LOKI_SECRET_NAME # this SA has the permissions to `get /metrics`
      key: token
    interval: 15s
    scheme: https
    tlsConfig: 
      insecureSkipVerify: true
    port: http-metrics
  namespaceSelector:
    matchNames:
    - openshift-user-workload-monitoring
  selector:
    matchLabels:
      app: loki-oauth

---
# and Prometheus itself
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  namespace: openshift-user-workload-monitoring
  name: prometheus
  labels:
    prometheus: sandbox-sre
spec:
  endpoints:
  - bearerTokenSecret:
      key: ""
    interval: 15s
    port: oauth2-proxy
    scheme: HTTPS
    tlsConfig: 
      caFile: /etc/prometheus/tls/tls.crt # volume mounted in the `prometheus` container of the prometheus pods
      serverName: "prometheus-oauth2.openshift-customer-monitoring.svc"
  namespaceSelector:
    matchNames:
    - openshift-user-workload-monitoring
  selector:
    matchLabels:
      app.kubernetes.io/instance: prometheus